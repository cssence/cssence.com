<!DOCTYPE html>
<html lang="en" class="c-link">
<head>
<title>Artificial regurgitation</title>
<meta name="description" content="Ethan Marcotte rightfully states that generative AI is doing nothing but hallucinating; and thereâ€™s more.">
<link rel="alternate" type="text/html" href="https://mas.to/@CSSence/114580701906387003" title="Thread on mas.to">
</head>
<body>
<main>
<article>
<header>
<h1>Artificial regurgitation</h1>
<p><i>Link</i><br><time>2025-05-27T16:19:21Z</time></p>
</header>
<div>
<h2 class="visually-hidden" id="comments">Message thread</h2>
<article>
<h3><span data-href="https://mas.to/@CSSence/114580701906387003"><b>Matthias ZÃ¶chling</b> wrote on <time>2025-05-27T16:19:21Z</time></span></h3>
<blockquote cite="https://ethanmarcotte.com/wrote/hallucinating/">
<p>Everythingâ€”<em>everything</em>â€”that comes out of these â€œAIâ€ platforms is a â€œhallucination.â€</p>
</blockquote>
<p>Spot on, @beep@follow.ethanmarcotte.com, as always.<br><span aria-hidden="true">ğŸ”— </span><a href="https://ethanmarcotte.com/wrote/hallucinating/">â€œHallucinating.â€</a></p>
</article>
<article>
<h3><span data-href="https://mas.to/@CSSence/114580701906387003"><b>Matthias ZÃ¶chling</b> wrote on <time>2025-05-27T16:27:18Z</time></span></h3>
<p data-chain="continue"><small>Continued from previous comment.</small></p>
<p>And if you are interested in an ever so thorough take on the subject of AI, I highly recommend this @btconf@mastodon.social talk by @tink@w3c.social:<br><span aria-hidden="true">ğŸ”— </span><a href="https://youtu.be/fyRxd072JrA">â€œThere is no spoonâ€</a></p>
</article>
<article>
<h3><span data-href="https://mas.to/@CSSence/114580978161561075"><b>Matthias ZÃ¶chling</b> wrote on <time>2025-05-27T17:29:36Z</time></span></h3>
<p data-chain="continue"><small>Continued from previous comment.</small></p>
<p>Having watched LÃ©onieâ€™s talk this morning, I was about to write something along the lines of: If AI can help a blind person â€œseeâ€ the world around them in real time, Iâ€™m all for it. But if it helps you write an e-mail that nobody cared about in the first place, itâ€™s just a waste of energy.</p>
<p>But apparently I can simply quote <a href="https://front-end.social/@hdv/114580684112012591">@hdv@front-end.social:</a></p>
<blockquote cite="https://front-end.social/@hdv/114580684112012591">
<p>I do think usefulness can outweigh ethical issues in some very specific use cases, eg if users want to make use of these tools to remove accessibility barriers theyâ€™re affected by</p>
</blockquote>
<p>So now I got two more blog posts to read. Iâ€™ll start with<br><span aria-hidden="true">ğŸ”— </span><a href="https://hidde.blog/ethical-ai/">â€œIs â€˜ethical AIâ€™ an oxymoron?â€</a><br>â€¦</p>
</article>
<article>
<h3><span data-href="https://mas.to/@CSSence/114580999696745649"><b>Matthias ZÃ¶chling</b> wrote on <time>2025-05-27T17:35:04Z</time></span></h3>
<p data-chain="continue"><small>Continued from previous comment.</small></p>
<p>â€¦ and then move on to @adactio@mastodon.socialâ€™s<br><span aria-hidden="true">ğŸ”— </span><a href="https://adactio.com/journal/21933">â€œUsesâ€</a><br>
with the following opening line:</p>
<blockquote cite="https://adactio.com/journal/21933">
<p>I donâ€™t use large language models.</p>
</blockquote>
<p>I feel seen.</p>
</article>
<article>
<h3><a href="https://follow.ethanmarcotte.com/@beep/114581112315803417"><b>Ethan Marcotte</b> wrote on <time>2025-05-27T18:03:43Z</time></a></h3>
<p data-chain="reply"><small>In reply to: <span>@CSSence@mas.to</span>.</small></p>
<p>Thank you, Matthiasâ€”I really appreciate that.</p>
<p>(And this is a wonderful thread youâ€™ve pulled together. Thanks for that, too.)</p>
</article>
<article>
<h3><a href="https://mastodon.social/@brianstorms/114581767648611297"><b>Brian Dear</b> wrote on <time>2025-05-27T18:30:33Z</time></a></h3>
<p data-chain="reply"><small>In reply to: <span>@CSSence@mas.to</span>.</small></p>
<p>They thought they were creating Artifical Intelligence.</p>
<p>What they actually were creating is Artificial Hallucination.</p>
</article>
<article>
<h3><a href="https://mastodon.social/@simonrjones/114581412155750096"><b>Simon Jones</b> wrote on <time>2025-05-27T19:19:58Z</time></a></h3>
<p data-chain="reply"><small>In reply to: <span>@CSSence@mas.to</span>.</small></p>
<p>Agree. I made the same point at a CMS conference I was on a panel a few weeks ago. Everything is a hallucination.</p>
</article>
<article data-unavailable="moderation">
<h3>Comment&nbsp;8<!-- https://mastodon.online/@carpetbomberz/114581546877611979 2025-05-27T19:54:14Z --> is unavailable</h3>
<p>Legal or technical reasons may be the cause.</p>
</article>
<article>
<h3><span data-href="https://mas.to/@CSSence/114581618792922471"><b>Matthias ZÃ¶chling</b> wrote on <time>2025-05-27T20:12:31Z</time></span></h3>
<p data-chain="reply"><small>In reply to: <span>@beep@follow.ethanmarcotte.com</span>.</small></p>
<p>Youâ€™re too kind, Ethan.</p>
<p>So yeah, ethics aside, it only took copyright infringements and vast amounts of energy to produce hallucinations. And if we use these hallucinations to generate new content, itâ€™ll become new training data. Garbage in, garbage out, on a loop. AI regurgitation, reminds me of <a href="https://www.youtube.com/shorts/DyEgh-kkkAA">reuploading to Youtube over and over again.</a></p>
<p>At least we already see the resistance, people putting â€œ100% human-madeâ€ stickers on their blogs.</p>
</article>
<article>
<h3><a href="https://mastodon.social/@brianstorms/114581767648611297"><b>Brian Dear</b> wrote on <time>2025-05-27T20:50:22Z</time></a></h3>
<p data-chain="reply"><small>In reply to: <span>@CSSence@mas.to</span>.</small></p>
<p>So in the end, youtube videos of youtube videos uploaded as youtube videos which in turn get uploaded as youtube videos, each generation worse like going from 4K to HD to VHS to a blurry mess; in the end we get the "gray goo" everyone feared was coming with nanobots, only itâ€™s the â€œAI slopâ€ versionâ€¦ hopefully only digital and not rendered in actual moleculesâ€¦</p>
</article>
</div>
</article>
</main>
</body>
</html>
